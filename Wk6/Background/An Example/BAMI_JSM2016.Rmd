---
title: "Benchmarking and assessment for multiple imputation"
author: "Gerko Vink"
date: "JSM 2016"
output: ioslides_presentation
bibliography: bibliography.bib

---
## Disclaimer

This presentation is about work in progress and is made solely by myself.

Images are bluntly borrowed from other sources; mostly without specific consent but with the conjugate prior that the authors would not care at all. 

Some of the information and ideas come from joint contemplation and/or work with Stef van Buuren, Andrew Gelman, Jeroen Pannekoek, Shahab Jolani and Laura Boeschoten. 

The following institutions allow me to cultivate my creativity
<center>
<img src="logo_5.png" alt="HTML5 Icon" width = 80%>
</center>

##Popularity of multiple imputation
<center>
<img src="figures/MI_wos.pdf" alt="HTML5 Icon" width = 80%>
</center>

The number of publications that have ‘multiple imputation’ as a topic (Web of Science$^{tm}$ Citation Reports, retrieved on August 1 2016)
<div class="notes">
Multiple imputation as a technique for doing inference on incomplete data is more popular than ever. It is also becoming increasingly more accepted.

Take this graph of WoS that displays the number of publications that have MI as a topic. 

Many of these publications consider imputation methodology. Methodology that is very often used. 
</div>

## How good is new methodology
The quality of a solution obtained by multiple imputation depends on 

1. the statistical properties of the incomplete data 
2. the inference problem with respect to the assumptions
3. the degree to which an imputation procedure is able to capture these properties when modeling missing values on the given data. 

<div class="notes">
In general it holds that modeling missing data becomes more challenging when the amount of missingness increases. 
However, when (strong) relations in the data are present, the observed parts can hold great predictive power for the models that estimate the missingness. In that case, multiple imputation would be substantially more efficient than the ubiquitous listwise deletion.

as reviewer and editor into problems - discuss some of these problems with you. 
</div>

##How is new methodology evaluated
When evaluating the statistical properties (and thereby the practical applicability) of new imputation methodology, researchers most often make use of simulation studies. 

1. a complete data set is usually generated from a statistical model
2. another model is used to induce missingness
3. a set of evaluation criteria is postulated to evaluate the performance of the imputation method. 

However, no golden standard has been established 

- as a result, validity of the simulation and evaluation procedures may differ tremendously from one developer to another.

<div class="notes">
as reviewer and editor into problems

discuss some of these problems with you. 
</div>

##Potential problems
This lack of consensus brings forth a chain of potential problems in the objective assessment of the performance of imputation routines that may lead to suboptimal use of multiple imputation in practice.

1. problems with data generation
2. problems with missingness generation 
3. problems with performance evaluation. 

##Data generation
1. Data are often generated following the model (or distribution) that is also used for imputing the data. 
    - Evaluated conditions are in favor of the problem that is studied. 
    - Although such procedures may be statistically relevant, the approach would be no good for even the simplest case. 

2. Data are often generated such that the problem that is being studied is most pronounced. 
    - This often results in simulated data that contains very valuable information structures
    - i.e. the correlations between groups of variables may be very pronounced. 

<div class="notes">
To evaluate the ability of an imputation routine to handle the nonresponse model, a form of truth has to be established. However, when generating data, two easily overlooked problems may arise.

1. The performance of the imputation approach is then deemed good, which is no surprise as the 
2. In other words, no matter what type of missingness is induced, the observed parts of the data may still hold much, if not all, of the information about the missing part and the performance of the imputation procedure is not surprisingly evaluated as very good. 
</div>

## Missingness generation

1. The missing data generation procedure is insufficiently described
2. The induced MAR mechanism is spurious
<center>
<img src="figures/plot_mmech.pdf" alt="HTML5 Icon" width = 100%>
</center>
3. MCAR missingness is often not considered
4. Different percentages are used

<div class="notes">
I only focus here ignorable
Aside from incompatible models...

In order to obtain valid imputation inference, the imputation model must capture the essence of the true nonresponse mechanism (Meng, 1994).
The model - if any - that is used to generate the missingness is usually assumed to be random (MAR) or completely random (MCAR)
It is also important for the evaluation to have an idea about the missingness problem - MCAR
</div>

##Performance evaluation
1. The focus often lies on accuracy (how well can the method reproduce the original data)
2. The performance of imputation procedures on distributional properties is often ignored in simulation studies
    - even though the estimates on the analysis level may be justified, some methods can yield imputations that may seem completely invalid to applied researchers. 
3. It is not necessary to take sampling variation into account (e.g. Vink and Van Buuren, 2014). 
4. Qualitative evaluation of the performance is often ignored. 
    - A method may perform badly, but if it still outperforms every other approach, it may yet be of great practical relevance.
    
<div class="notes">
The evaluation criteria used to assess imputation performance vary from one developer to another. This is not surprising as people from di↵erent fields could have a di↵erent focus on the problem at hand. However, because mul- tiple imputation was designed as a mode for statistical inference, a minimal set of statistical properties should at least be evaluated. I highlight four aspects of evaluation that should be considered when evaluation imputation routines.

1. given the framework provided by Rubin (1987), statistical properties such as bias, confidence intervals and the coverage rate of the confidence intervals should be studied. After all, the 95% confidence interval should contain the ‘true’ value at least 95 out of 100 times (Neyman, 1934, p. 591).
 
2. For example, one could very accurately estimate average human height by filling in negative values and values that are unrealistically large. While the obtained inference could still be valid under such imputations, the plausibility of the imputed values given the observed data should be under scrutiny. Rather, one would prefer an imputation technique to yield both valid inference and plausible im- putations. It should be studied if an imputation method is prone to deliver such impractical results, and if so, under what conditions.

3. After all, we are interested only in the missing data mechanism, and are not considering the noise induced by the sampling mechanism for evaluation in such studies.

4. Comparing the performance of an imputation routine given a population (or true) parameter allows for quantitative evaluation. However, in order to pose qualitative statements about the performance on simulated con- ditions, comparative methodology is required. For example, when claiming that imputation performance is unacceptable when deviations from normal- ity become rather stringent, such performance is highly dependent on the simulation conditions that are used. For a well-balanced judgement about the severity of the performance drop, comparative simulations with e.g. non- parametric models should be executed. 
</div>

##Some more thougths
Imputation techniques are developed to solve distinct problems. 

- They are evaluated on their performance on these problems, but are potentially of great scientific use outside of their target application. 
- Such innovative applications remain unknown. 

Also, the target audience for multiple imputation consists of applied researchers from all scientific domains. 

- These researchers often lack the statistical knowledge to understand the methodology behind these imputation techniques. 
- How can these researchers decide what imputation technique would be suitable for their problem?

<div class="notes">

-ga verder met slide. 
-Helping applied scientists pays the bills, but I'd rather focus on new methodology. 
</div>

#Towards standardization
<center>
![](figures/bami.pdf)
</center>

<div class="notes">
I like to lovingly refer to this project with its abreviation; BAMI - which is how the Dutch refer to bami goreng, and indonesian fried noodle dish. We love it: we even have a battered deep-fried version of it that is eloquently called a bamihap. 
</div>

##Benchmarking and assessment
Integrate benchmarking into multiple imputation methodology

- a standardized set of benchmark routines for assessing the quality of multiple imputation methods. 

If we evaluate imputation techniques on a standardized set we solve two distinct problems:

1. A standardized set allows for a fair and thorough evaluation of the statistical properties of every imputation technique.
2. When each routine is put through a standardized evaluation procedure, we can make fair and justified comparisons between imputation techniques.

<div class="notes">
-Stellar performance is not the issue: wonderful methodology is constantly being developed. We just need some help in seperating the great ones. 
</div>

##This helps two camps

###Applied researchers
When it is possible to compare benchmarked techniques to one another, we can determine what would be the optimal imputation method for specific data problems. 
  
  - applied researchers can get the optimal imputation technology for their data, without the advanced statistical knowledge that is normally required when implementing multiple imputation techniques.

###Developers
Benchmarking brings gives an indication of the state-of-the-art

##
<center>
<img src="figures/path.pdf" alt="HTML5 Icon" width = 60%>
</center>


##Things left to do
- Further explore the common ground between experts on what to call `standard` in evaluating multiple imputation procedures
- Make BAMI online accessible
- Let online BAMI produce code to run offline
- Collect more data sets
- Implement into Stan

If you have thoughts on this: please e-mail me 

- G.Vink@uu.nl
- gv2249@columbia.edu

##Proposed standardized route
1. Obtain truth
    - model-based or design-based
2. Create valid missingness
    - i.e. cf. the method described by Brand (1999)
    - 10, 25 and 50 percent missingness
3. Simulate
    - leave out sampling variation
4. Evaluate imputations
    - bias, coverage, ciw
    - distributional characteristics vs observed plausibility
    - algorithmic convergence

##References

- Brand, J. (1999). Development, implementation and evaluation of multiple imputation strategies for the statistical analysis of incomplete data sets. PhD thesis, Erasmus University Rotterdam.

- Vink, G. and van Buuren, S. (2014). Pooling multiple imputations when the sample happens to be the population. arXiv preprint arXiv:1409.8542.


##

##
##Cooking vs multiple imputation. 

<div class="columns-2">
- study your data set
- find methodology
- ignore standard procedures
- **use experience and skills**
- eliminate dumb luck
- adjust the inference when needed
- use plausible imputations 
</div>

<div class="notes">
I know my physique does not show it, but eating is one of my fortes. I usually put my work on hold to take some serious time to cook a hearty meal for my family: I picture a meal, start from scratch, use fresh ingredients and never use a cookbook. I use my experience, the skills and a fail bit of dumb luck. If in the end I feel something is missing to create the taste I am after, I try to approach that taste as closely as possible with the tools and spices I have at hand. 

In the end, I try to make it as visually pleasing as possible: If you've ever tried to explain to a one or three year old that it tastes better than it looks - you know what I'm talking about. 
-To me, the process of multiple imputation is similar to cooking a meal: I try to approach it with the same care, effort and love that I put into cooking a meal. 
-Go through steps
-To me, using the blunt one-procedure-fits all imputation procedures that applied scientist often use feels like nuking tv-dinners. It may be okay - to some it may even taste like - but do we want our target audience to settle for less than stellar?
</div>